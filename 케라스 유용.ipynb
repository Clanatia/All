{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.]\n",
      " [ 7.]\n",
      " [ 8.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Lambda, Input\n",
    "from keras.models import Model\n",
    "\n",
    "x = Input((1,))\n",
    "y = Lambda(lambda x:x +1)(x)\n",
    "m = Model(x,y)\n",
    "\n",
    "yp = m.predict_on_batch([5,6,7])\n",
    "print(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 36.]\n",
      " [ 49.]\n",
      " [ 64.]]\n"
     ]
    }
   ],
   "source": [
    "def kproc(x):\n",
    "    return x**2 + 2*x +1\n",
    "\n",
    "def kshape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "x = Input((1,))\n",
    "y = Lambda(kproc,kshape)(x)\n",
    "m = Model(x,y)\n",
    "yp = m.predict_on_batch([5,6,7])\n",
    "print(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          2.          3.          1.          0.          1.          1.\n",
      "   0.          1.        ]\n",
      " [ 3.          4.          6.          1.33333349  0.33333349  1.66666651\n",
      "   1.77777815  0.11111122  2.77777719]]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def kproc_concat(x):\n",
    "    m = K.mean(x,axis=1,keepdims=True)\n",
    "    d1 = K.abs(x-m)\n",
    "    d2 = K.square(x-m)\n",
    "    return K.concatenate([x,d1,d2],axis=1)\n",
    "\n",
    "def kshape_concat(input_shape):\n",
    "    output_shape = list(input_shape)\n",
    "    output_shape[1] *=3\n",
    "    return tuple(output_shape)\n",
    "\n",
    "x = Input((3,))\n",
    "y = Lambda(kproc_concat,kshape_concat)(x)\n",
    "m = Model(x,y)\n",
    "\n",
    "yp = m.predict_on_batch([[1,2,3],[3,4,6]])\n",
    "print(yp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true,y_pred):\n",
    "    return K.mean(K.square(y_pred-y_true),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          2.          3.          1.          0.          1.          1.\n",
      "   0.          1.        ]\n",
      " [ 3.          4.          6.          1.33333349  0.33333349  1.66666651\n",
      "   1.77777815  0.11111122  2.77777719]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def kproc_concat(x):\n",
    "    m = tf.reduce_mean(x,axis=1,keep_dims=True)\n",
    "    d1 = tf.abs(x-m)\n",
    "    d2 = tf.square(x-m)\n",
    "    return tf.concat([x,d1,d2],axis=1)\n",
    "\n",
    "def kshape_concat(input_shape):\n",
    "    output_shape = list(input_shape)\n",
    "    output_shape[1] *=3\n",
    "    return tuple(output_shape)\n",
    "\n",
    "x = Input((3,))\n",
    "y = Lambda(kproc_concat,kshape_concat)(x)\n",
    "m = Model(x,y)\n",
    "\n",
    "yp = m.predict_on_batch([[1,2,3],[3,4,6]])\n",
    "print(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [ 4.96334887  6.93682814  8.91030693]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "\n",
    "from keras import initializers\n",
    "igu = initializers.get('glorot_uniform')\n",
    "iz = initializers.get('zeros')\n",
    "\n",
    "class Sample(Layer):\n",
    "    def __init__(self,No,**kwargs):\n",
    "        self.No = No\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def build(self,inshape):\n",
    "        self.w = self.add_weight(\"w\",(inshape[1],self.No),initializer=igu)\n",
    "        self.b = self.add_weight(\"b\",(self.No,),initializer=iz)\n",
    "        super().build(inshape)\n",
    "        \n",
    "    def call(self,x):\n",
    "        return K.dot(x,self.w)+self.b\n",
    "    \n",
    "    def compute_output_shape(self,inshape):\n",
    "        return (inshape[0],self.No)\n",
    "    \n",
    "x = np.array([0,1,2,3,4])\n",
    "y = x*2+1\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Sample(1,input_shape=(1,)))\n",
    "model.compile('SGD',mean_squared_error)\n",
    "model.fit(x[:2],y[:2],epochs=1000,verbose=0)\n",
    "print(\"Predictions:\", model.predict(x[2:]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 0.224, acc = 0.933\n",
      "Epoch 1: loss = 0.172, acc = 0.948\n",
      "Epoch 2: loss = 0.149, acc = 0.956\n",
      "Epoch 3: loss = 0.135, acc = 0.962\n",
      "Epoch 4: loss = 0.128, acc = 0.963\n",
      "Epoch 5: loss = 0.117, acc = 0.967\n",
      "Epoch 6: loss = 0.118, acc = 0.966\n",
      "Epoch 7: loss = 0.107, acc = 0.968\n",
      "Epoch 8: loss = 0.104, acc = 0.970\n",
      "Epoch 9: loss = 0.108, acc = 0.969\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "\n",
    "class DNN():\n",
    "    def __init__(self,Nin,Nh,Nout):\n",
    "        self.X_ph = tf.placeholder(tf.float32,shape=(None,Nin))\n",
    "        self.L_ph = tf.placeholder(tf.float32,shape=(None,Nout))\n",
    "        \n",
    "        H = Dense(Nh[0],activation='relu')(self.X_ph)\n",
    "        H = Dropout(0.5)(H)\n",
    "        H = Dense(Nh[1],activation='relu')(H)\n",
    "        H = Dropout(0.25)(H)\n",
    "        self.Y_tf = Dense(Nout,activation='softmax')(H)\n",
    "        \n",
    "        self.Loss_tf = tf.reduce_mean(categorical_crossentropy(self.L_ph,self.Y_tf))\n",
    "        self.Train_tf = tf.train.AdamOptimizer().minimize(self.Loss_tf)\n",
    "        self.Acc_tf = categorical_accuracy(self.L_ph,self.Y_tf)\n",
    "        self.Init_tf = tf.global_variables_initializer()\n",
    "        \n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def Data_func():\n",
    "    (X_train,Y_train),(X_test,Y_test) = datasets.mnist.load_data()\n",
    "    Y_train = np_utils.to_categorical(Y_train)\n",
    "    Y_test = np_utils.to_categorical(Y_test)\n",
    "    \n",
    "    L,W,H = X_train.shape\n",
    "    X_train = X_train.reshape(-1,W*H)\n",
    "    X_test = X_test.reshape(-1,W*H)\n",
    "    X_train = X_train/255\n",
    "    X_test = X_test/255\n",
    "    return (X_train,Y_train), (X_test,Y_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run(model,data,sess,epochs,batch_size = 100):\n",
    "    (X_train,Y_train),(X_test,Y_test) = data\n",
    "    sess.run(model.Init_tf)\n",
    "    with sess.as_default():\n",
    "        N_tr = X_train.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            for b in range(N_tr//batch_size):\n",
    "                X_tr_b = X_train[batch_size*(b-1):batch_size*b]\n",
    "                Y_tr_b = Y_train[batch_size*(b-1):batch_size*b]\n",
    "                \n",
    "                model.Train_tf.run(feed_dict={model.X_ph:X_tr_b,model.L_ph:Y_tr_b,K.learning_phase():1})\n",
    "                \n",
    "            loss = sess.run(model.Loss_tf,feed_dict={model.X_ph:X_test,model.L_ph:Y_test, K.learning_phase():0})\n",
    "            acc = model.Acc_tf.eval(feed_dict={model.X_ph:X_test,model.L_ph:Y_test,K.learning_phase():0})\n",
    "            print(\"Epoch {0}: loss = {1:.3f}, acc = {2:.3f}\".format(epoch,loss,np.mean(acc)))\n",
    "            \n",
    "def main():\n",
    "    Nin = 784\n",
    "    Nh = [100,50]\n",
    "    num_class =10\n",
    "    \n",
    "    data = Data_func()\n",
    "    model = DNN(Nin,Nh,num_class)\n",
    "    run(model,data,sess,10,100)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
